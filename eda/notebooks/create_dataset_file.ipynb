{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d34698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e23dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_ids = [\"LL\", \"ZM\", \"VV\", \"YL\", \"YT\"] \n",
    "activity_ids = [\"sitting\", \"walking\", \"running\", \"lying\"]\n",
    "sensor_ids = [\"ax\", \"ay\", \"az\", \"gx\", \"gy\", \"gz\",\"mx\", \"my\", \"mz\"]\n",
    "columns_order = ['participant_id', 'activity_id', 'timestamp', 'ax', 'ay', 'az', 'gx', 'gy', 'gz', 'mx', 'my', 'mz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd4600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list():\n",
    "    \"\"\"\n",
    "    Fetch the list of files from the GitHub repository\n",
    "    \"\"\"\n",
    "    url = f\"https://api.github.com/repos/COEN498-691-PROJECT/ML_project/contents/data/raw?ref=main\"\n",
    "    response = requests.get(url)\n",
    "    files = response.json()\n",
    "    return files\n",
    "\n",
    "def filter_files(files, participant_ids, activity_ids, sensor_ids):\n",
    "    \"\"\"\n",
    "    Filter the list of files based on the list of participant IDs, activity IDs, and sensor IDs\n",
    "    \"\"\"\n",
    "    filtered_files_url = []\n",
    "    for file in files:\n",
    "        file_name = file['name']\n",
    "        if any(pid.upper() in file_name for pid in participant_ids) and \\\n",
    "           any(aid in file_name for aid in activity_ids) and \\\n",
    "           any(sid.upper() in file_name for sid in sensor_ids):\n",
    "            filtered_files_url.append( (file['download_url'], file_name) )\n",
    "    return filtered_files_url\n",
    "\n",
    "def add_columns(df, file_url):\n",
    "    \"\"\"\n",
    "    Add participant ID and activity ID to the dataframe\n",
    "    \"\"\"\n",
    "    parts = file_url.split('_')\n",
    "    participant_id = parts[0]\n",
    "    activity_id = parts[1]\n",
    "    df['participant_id'] = participant_id\n",
    "    df['activity_id'] = activity_id\n",
    "    return df\n",
    "\n",
    "def load_dataframes(file_urls: tuple):\n",
    "    \"\"\"\n",
    "    Load dataframes from the list of file URLs and add participant and activity IDs columns\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    for file_url, file_name in file_urls:\n",
    "        df = pd.read_csv(file_url)\n",
    "        df = add_columns(df, file_name)\n",
    "        df_list.append(df)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20789ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_file(df_list):\n",
    "    \"\"\"\n",
    "    Create the final dataset file by combining all dataframes, cleaning, and saving to CSV\n",
    "    \"\"\"\n",
    "    combined_df = pd.concat(df_list, ignore_index=True) # Combine all dataframes\n",
    "    combined_df.drop(columns=['PacketNumber', 'DataLength', 'TypeTag', 'ProtocolVersion', 'EmotiBitTimestamp', 'DataReliability'], errors='ignore', inplace=True) # Drop unnecessary columns\n",
    "    combined_df.rename(columns={'LocalTimestamp': 'timestamp',\n",
    "                                'AX': 'ax',\n",
    "                                'AY': 'ay',\n",
    "                                'AZ': 'az',\n",
    "                                'GX': 'gx',\n",
    "                                'GY': 'gy',\n",
    "                                'GZ': 'gz',\n",
    "                                'MX': 'mx',\n",
    "                                'MY': 'my',\n",
    "                                'MZ': 'mz'}, inplace=True) # Rename columns for consistency\n",
    "    combined_df = combined_df[columns_order] # Reorder columns\n",
    "    combined_df = combined_df.groupby(['timestamp', 'activity_id', 'participant_id']).mean().reset_index() # Handle duplicates by averaging\n",
    "    combined_df.sort_values(by=['timestamp'], inplace=True) # Sort by timestamp (ascending)\n",
    "    combined_df.to_csv('../../data/processed/COEN498-691_HAR_dataset.csv', index=False, date_format='%Y-%m-%d %H:%M:%S.%f') # Save to CSV\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb2f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = get_file_list()\n",
    "filtered_files_url = filter_files(file_list, participant_ids, activity_ids, sensor_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9c3a155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LocalTimestamp  EmotiBitTimestamp  PacketNumber  DataLength TypeTag  \\\n",
      "0    1.760382e+09          1325026.0         21641           1      AX   \n",
      "1    1.760382e+09          1325066.0         21657           2      AX   \n",
      "2    1.760382e+09          1325106.0         21657           2      AX   \n",
      "3    1.760382e+09          1325146.0         21675           3      AX   \n",
      "4    1.760382e+09          1325186.0         21675           3      AX   \n",
      "5    1.760382e+09          1325226.0         21675           3      AX   \n",
      "6    1.760382e+09          1325266.0         21691           2      AX   \n",
      "7    1.760382e+09          1325306.0         21691           2      AX   \n",
      "8    1.760382e+09          1325346.0         21708           3      AX   \n",
      "9    1.760382e+09          1325386.0         21708           3      AX   \n",
      "\n",
      "   ProtocolVersion  DataReliability     AX participant_id activity_id  \n",
      "0                1              100  0.596             LL       lying  \n",
      "1                1              100  0.710             LL       lying  \n",
      "2                1              100  0.670             LL       lying  \n",
      "3                1              100  0.664             LL       lying  \n",
      "4                1              100  0.688             LL       lying  \n",
      "5                1              100  0.727             LL       lying  \n",
      "6                1              100  0.703             LL       lying  \n",
      "7                1              100  0.703             LL       lying  \n",
      "8                1              100  0.725             LL       lying  \n",
      "9                1              100  0.677             LL       lying  \n"
     ]
    }
   ],
   "source": [
    "df_list = load_dataframes(filtered_files_url)\n",
    "print(df_list[0].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6152ebb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      timestamp activity_id participant_id     ax     ay        az        gx  \\\n",
      "0  1.760380e+09     sitting             ZM -0.001  0.849  0.484333 -0.569667   \n",
      "1  1.760380e+09     sitting             ZM -0.008  0.850  0.483000 -0.610000   \n",
      "2  1.760380e+09     sitting             ZM  0.006  0.852  0.480000 -0.519000   \n",
      "3  1.760380e+09     sitting             ZM  0.001  0.851  0.477000 -0.610000   \n",
      "4  1.760380e+09     sitting             ZM -0.002  0.853  0.481000 -0.671000   \n",
      "5  1.760380e+09     sitting             ZM  0.008  0.841  0.479000 -0.427000   \n",
      "6  1.760380e+09     sitting             ZM -0.005  0.851  0.484000 -0.610000   \n",
      "7  1.760380e+09     sitting             ZM -0.002  0.857  0.481000 -0.366000   \n",
      "8  1.760380e+09     sitting             ZM  0.002  0.847  0.478000 -0.519000   \n",
      "9  1.760380e+09     sitting             ZM -0.004  0.853  0.467000 -0.977000   \n",
      "\n",
      "      gy        gz    mx         my    mz  \n",
      "0 -0.305  0.305333  91.0  14.666667 -27.0  \n",
      "1 -0.214  0.214000  90.0  15.000000 -28.0  \n",
      "2 -0.580  0.183000  90.0  15.000000 -27.0  \n",
      "3 -0.702  0.366000  91.0  14.000000 -28.0  \n",
      "4  0.061  0.397000  90.0  14.000000 -29.0  \n",
      "5 -0.275  0.244000  91.0  14.000000 -27.0  \n",
      "6  0.671 -0.031000  91.0  14.000000 -27.0  \n",
      "7  0.702  0.244000  91.0  14.000000 -28.0  \n",
      "8 -0.061  0.061000  90.0  14.000000 -28.0  \n",
      "9 -0.153 -0.122000  91.0  15.000000 -27.0  \n"
     ]
    }
   ],
   "source": [
    "df_final = create_dataset_file(df_list)\n",
    "print(df_final.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
