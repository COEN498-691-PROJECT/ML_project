{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdklC_L_Ibpc",
        "outputId": "38fbab6a-d9d4-47ac-b591-6badb9bd5248"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Environment setup complete, Google Drive mounted.\n",
            "Loaded pretrained model weights from /content/drive/MyDrive/mlp_har_model.h5\n",
            "Starting MLP model training (Epochs=10)...\n",
            "Model training complete.\n"
          ]
        }
      ],
      "source": [
        "# Install Gradio (using -q for quiet mode)\n",
        "!pip install gradio -q\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import gradio as gr\n",
        "import warnings\n",
        "import os\n",
        "import joblib # Import joblib for loading Logistic Regression model\n",
        "\n",
        "print(\"Environment setup complete, Google Drive mounted.\")\n",
        "\n",
        "# --- Configuration and Data Loading ---\n",
        "# Please modify this path according to your Google Drive\n",
        "dataset_path = '/content/drive/MyDrive/HAR prepocessed dataset/COEN498-691_HAR_preprocessed_dataset.csv'\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    raise FileNotFoundError(f\"Dataset file not found, please check the path: {dataset_path}\")\n",
        "\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# 1. Prepare Data (consistent with original notebook)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(['activity_id', 'participant_id'], axis=1)\n",
        "y = df['activity_id']\n",
        "\n",
        "# Split data (for training Scaler and Encoder)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 2. Preprocessing\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
        "\n",
        "# 3. Model Definition (consistent with original notebook architecture)\n",
        "n_features = X_train_scaled.shape[1]\n",
        "n_classes = y_train_encoded.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "# UserWarning: Do not pass an `input_shape`/`input_dim`...\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    model.add(Dense(128, activation='relu', input_shape=(n_features,)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "# TODO load pretrained model weights file\n",
        "weights_path = '/content/drive/MyDrive/mlp_har_model.h5' # <--- Please adjust this path to your actual weights file\n",
        "if os.path.exists(weights_path):\n",
        "    try:\n",
        "        model.load_weights(weights_path)\n",
        "        print(f\"Loaded pretrained model weights from {weights_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading weights from {weights_path}: {e}. Model will be trained from scratch.\")\n",
        "else:\n",
        "    print(f\"Pretrained weights file not found at {weights_path}. Model will be trained from scratch.\")\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 4. Model Training (reduced epochs for quick demonstration)\n",
        "print(\"Starting MLP model training (Epochs=10)...\")\n",
        "# Note: The original notebook used epochs=50 for high accuracy,\n",
        "# we use 10 here for faster demonstration.\n",
        "model.fit(X_train_scaled, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# 5. Define Gradio Prediction Function and Label Mapping\n",
        "activity_ids_order = encoder.categories_[0].tolist()\n",
        "ACTIVITY_NAMES = {\n",
        "    1: \"sitting\",\n",
        "    2: \"walking\",\n",
        "    3: \"running\",\n",
        "    4: \"lying\"\n",
        "}\n",
        "LABEL_MAP = {i: ACTIVITY_NAMES.get(activity_ids_order[i], f\"Activity ID {activity_ids_order[i]}\")\n",
        "             for i in range(len(activity_ids_order))}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Tjmh8Jj5Fk0",
        "outputId": "67c8719c-2f32-4953-f755-a1ce437373c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93144e03"
      },
      "source": [
        "# Task\n",
        "Train and integrate a Logistic Regression model with the existing MLP model, then update the Gradio interface to display activity predictions and confidence scores from both models side-by-side for comparison."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0307218c"
      },
      "source": [
        "## Train Logistic Regression Model\n",
        "\n",
        "### Subtask:\n",
        "Define and train a Logistic Regression model using the existing preprocessed training data (`X_train_scaled`, `y_train`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e86045a"
      },
      "source": [
        "**Reasoning**:\n",
        "Import `LogisticRegression` from `sklearn.linear_model`, instantiate it with `max_iter=1000` and `random_state=42`, and then train the model using `X_train_scaled` and `y_train`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97391c08",
        "outputId": "2ca9be2b-e5f1-4093-d79b-8af156a6bb3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained Logistic Regression model from /content/drive/MyDrive/logistic_regression_model.pkl\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg_model_path = '/content/drive/MyDrive/logistic_regression_model.pkl'\n",
        "\n",
        "if os.path.exists(log_reg_model_path):\n",
        "    try:\n",
        "        log_reg_model = joblib.load(log_reg_model_path)\n",
        "        print(f\"Loaded pretrained Logistic Regression model from {log_reg_model_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading Logistic Regression model from {log_reg_model_path}: {e}. Model will be trained from scratch.\")\n",
        "        # Instantiate the Logistic Regression model\n",
        "        # Set max_iter to a sufficiently large number for convergence\n",
        "        # Set random_state for reproducibility\n",
        "        log_reg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "        # Train the Logistic Regression model\n",
        "        log_reg_model.fit(X_train_scaled, y_train)\n",
        "        print(\"Logistic Regression model trained successfully from scratch.\")\n",
        "else:\n",
        "    print(f\"Pretrained Logistic Regression model file not found at {log_reg_model_path}. Model will be trained from scratch.\")\n",
        "    # Instantiate the Logistic Regression model\n",
        "    # Set max_iter to a sufficiently large number for convergence\n",
        "    # Set random_state for reproducibility\n",
        "    log_reg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "    # Train the Logistic Regression model\n",
        "    log_reg_model.fit(X_train_scaled, y_train)\n",
        "    print(\"Logistic Regression model trained successfully from scratch.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dab8923"
      },
      "source": [
        "## Update Gradio Interface for Combined Prediction\n",
        "\n",
        "### Subtask:\n",
        "Modify the `predict_activity` function and the Gradio interface to incorporate predictions from both the MLP and the newly trained Logistic Regression models. The output should display the predicted activity and confidence from both models, clearly distinguishing between them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff740425"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires updating the `predict_activity` function to include predictions from both MLP and Logistic Regression models and modifying the Gradio interface to display both. This involves getting predictions from both models on the scaled input, determining their confidence, and formatting a combined output string for the Gradio interface.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 940
        },
        "id": "9811f75a",
        "outputId": "80d2953f-adbc-4d34-a958-a672ea77042c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Gradio Interface Launched with Switchable Models ---\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://918231232d1fb2cca8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://918231232d1fb2cca8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) MLP ####################\n",
            "DEBUG: MLP Probabilities: [2.2309073e-26 1.2840619e-34 1.3111069e-27 1.0000000e+00]\n",
            "DEBUG: predict_activity is about to return: \n",
            "# Activity Prediction Results\n",
            "\n",
            "## MLP Model Prediction\n",
            "Predicted Activity: **lying**\n",
            "Confidence: 1.0000\n",
            "\n",
            "### MLP Probability Distribution\n",
            "lying: 1.0000\n",
            "sitting: 0.0000\n",
            "running: 0.0000\n",
            "walking: 0.0000\n",
            "...\n",
            "(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) MLP ####################\n",
            "DEBUG: MLP Probabilities: [2.2309073e-26 1.2840619e-34 1.3111069e-27 1.0000000e+00]\n",
            "DEBUG: predict_activity is about to return: \n",
            "# Activity Prediction Results\n",
            "\n",
            "## MLP Model Prediction\n",
            "Predicted Activity: **lying**\n",
            "Confidence: 1.0000\n",
            "\n",
            "### MLP Probability Distribution\n",
            "lying: 1.0000\n",
            "sitting: 0.0000\n",
            "running: 0.0000\n",
            "walking: 0.0000\n",
            "...\n",
            "(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) MLP ####################\n",
            "DEBUG: MLP Probabilities: [2.2309073e-26 1.2840619e-34 1.3111069e-27 1.0000000e+00]\n",
            "DEBUG: predict_activity is about to return: \n",
            "# Activity Prediction Results\n",
            "\n",
            "## MLP Model Prediction\n",
            "Predicted Activity: **lying**\n",
            "Confidence: 1.0000\n",
            "\n",
            "### MLP Probability Distribution\n",
            "lying: 1.0000\n",
            "sitting: 0.0000\n",
            "running: 0.0000\n",
            "walking: 0.0000\n",
            "...\n",
            "(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) MLP ####################\n",
            "DEBUG: MLP Probabilities: [2.2309073e-26 1.2840619e-34 1.3111069e-27 1.0000000e+00]\n",
            "DEBUG: predict_activity is about to return: \n",
            "# Activity Prediction Results\n",
            "\n",
            "## MLP Model Prediction\n",
            "Predicted Activity: **lying**\n",
            "Confidence: 1.0000\n",
            "\n",
            "### MLP Probability Distribution\n",
            "lying: 1.0000\n",
            "sitting: 0.0000\n",
            "running: 0.0000\n",
            "walking: 0.0000\n",
            "...\n",
            "(5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) Logistic Regression ####################\n",
            "DEBUG: predict_activity is about to return: \n",
            "# Activity Prediction Results\n",
            "\n",
            "## Logistic Regression Model Prediction\n",
            "Predicted Activity: **walking**\n",
            "Confidence: 1.0000\n",
            "\n",
            "### Logistic Regression Probability Distribution\n",
            "walking: 1.0000\n",
            "lying: 0.000...\n",
            "Created dataset file at: .gradio/flagged/dataset1.csv\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "def predict_activity(*args):\n",
        "    \"\"\"Gradio wrapper function for combined MLP and Logistic Regression prediction.\"\"\"\n",
        "\n",
        "\n",
        "    chosen_model = args[-1]\n",
        "\n",
        "    features = args[:-1]\n",
        "\n",
        "    try:\n",
        "        print(features, chosen_model, '####################')\n",
        "        sys.stdout.flush()\n",
        "\n",
        "        # Convert input and scale\n",
        "\n",
        "        input_data = np.array(features, dtype=np.float32).reshape(1, -1)\n",
        "        scaled_data = scaler.transform(input_data)\n",
        "\n",
        "        output_text = \"# Activity Prediction Results\\n\\n\"\n",
        "\n",
        "        if chosen_model == \"MLP\":\n",
        "            # ...\n",
        "            mlp_predictions_proba = model.predict(scaled_data, verbose=0)[0]\n",
        "            mlp_predicted_index = np.argmax(mlp_predictions_proba)\n",
        "            mlp_confidence = mlp_predictions_proba[mlp_predicted_index]\n",
        "            mlp_predicted_label = LABEL_MAP.get(mlp_predicted_index, f\"Unknown Index {mlp_predicted_index}\")\n",
        "\n",
        "            print(f\"DEBUG: MLP Probabilities: {mlp_predictions_proba}\")\n",
        "\n",
        "            output_text += \"## MLP Model Prediction\\n\"\n",
        "            output_text += f\"Predicted Activity: **{mlp_predicted_label}**\\n\"\n",
        "            output_text += f\"Confidence: {mlp_confidence:.4f}\\n\\n\"\n",
        "            output_text += \"### MLP Probability Distribution\\n\"\n",
        "            mlp_sorted_indices = np.argsort(mlp_predictions_proba)[::-1]\n",
        "            for i in mlp_sorted_indices:\n",
        "                label_name = LABEL_MAP.get(i, f\"Unknown Index {i}\")\n",
        "                output_text += f\"{label_name}: {mlp_predictions_proba[i]:.4f}\\n\"\n",
        "\n",
        "        elif chosen_model == \"Logistic Regression\":\n",
        "            # ... (Logistic Regression )\n",
        "            log_reg_predictions_proba = log_reg_model.predict_proba(scaled_data)[0]\n",
        "            log_reg_predicted_index = np.argmax(log_reg_predictions_proba)\n",
        "            log_reg_confidence = log_reg_predictions_proba[log_reg_predicted_index]\n",
        "\n",
        "            actual_log_reg_predicted_activity_id = log_reg_model.classes_[log_reg_predicted_index]\n",
        "            log_reg_predicted_label = ACTIVITY_NAMES.get(actual_log_reg_predicted_activity_id, f\"Unknown ID {actual_log_reg_predicted_activity_id}\")\n",
        "\n",
        "            output_text += \"## Logistic Regression Model Prediction\\n\"\n",
        "            output_text += f\"Predicted Activity: **{log_reg_predicted_label}**\\n\"\n",
        "            output_text += f\"Confidence: {log_reg_confidence:.4f}\\n\\n\"\n",
        "            output_text += \"### Logistic Regression Probability Distribution\\n\"\n",
        "\n",
        "            log_reg_sorted_indices = np.argsort(log_reg_predictions_proba)[::-1]\n",
        "            for i in log_reg_sorted_indices:\n",
        "                log_reg_actual_activity_id = log_reg_model.classes_[i]\n",
        "                log_reg_label_name = ACTIVITY_NAMES.get(log_reg_actual_activity_id, f\"Unknown ID {log_reg_actual_activity_id}\")\n",
        "                output_text += f\"{log_reg_label_name}: {log_reg_predictions_proba[i]:.4f}\\n\"\n",
        "        else:\n",
        "            output_text += \"Please select a model to predict with.\"\n",
        "\n",
        "        print(f\"DEBUG: predict_activity is about to return: \\n{output_text[:200]}...\")\n",
        "        return output_text\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        import traceback\n",
        "        error_details = traceback.format_exc()\n",
        "        print(f\"DEBUG: predict_activity caught an error: {e}\\nTraceback:\\n{error_details}\")\n",
        "        return f\"Error during prediction: {e}. Check console for traceback.\"\n",
        "\n",
        "# Configure Gradio Interface\n",
        "feature_names = X.columns.tolist()\n",
        "feature_inputs = [gr.Number(label=name, value=0.0) for name in feature_names]\n",
        "\n",
        "# Add model selection input\n",
        "model_selection_input = gr.Radio(\n",
        "    [\"MLP\", \"Logistic Regression\"],\n",
        "    label=\"Choose Model\",\n",
        "    value=\"MLP\" # Default selected model\n",
        ")\n",
        "\n",
        "# Combine feature inputs with model selection input\n",
        "all_inputs = feature_inputs + [model_selection_input]\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict_activity,\n",
        "    inputs=all_inputs, # Use all_inputs\n",
        "    outputs=gr.Markdown(label=\"Prediction Result\"),\n",
        "    title=\"Switchable Human Activity Recognition (HAR) Predictor\", # Updated title\n",
        "    description=\"Enter 37 sensor feature values, and select a model to predict the activity type.\", # Updated description\n",
        "    live=False\n",
        ")\n",
        "\n",
        "# Launch Gradio Application\n",
        "print(\"\\n--- Gradio Interface Launched with Switchable Models ---\")\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e5ebd6c"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the combined predictions from both the MLP and Logistic Regression models in the Gradio interface.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bef271e"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   A Logistic Regression model was successfully trained using the preprocessed training data (`X_train_scaled`, `y_train`) with `max_iter=1000` and `random_state=42`.\n",
        "*   The `predict_activity` function within the Gradio interface was updated to generate predictions from both the MLP and the newly trained Logistic Regression models.\n",
        "*   The Gradio interface now displays the predicted activity, confidence score, and full probability distribution for each model (MLP and Logistic Regression) side-by-side, formatted in Markdown for clear comparison.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The updated Gradio interface provides a practical tool for comparing the real-time predictions and confidence levels of two different machine learning models (MLP and Logistic Regression) on new inputs, which is valuable for understanding their respective strengths and weaknesses.\n",
        "*   As a next step, a quantitative evaluation of both models (MLP and Logistic Regression) on a held-out test set could be performed to compare their accuracy, precision, recall, and F1-score, providing a more rigorous assessment of their performance.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}